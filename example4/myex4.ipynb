{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rZnJaGTWQw0"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "\n",
    "# TensorFlow\n",
    "import os\n",
    "HOME = os.getenv('HOME')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # to get rid of the TF warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape, Flatten\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyv_i85IWInT"
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "url = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip'\n",
    "csv_path = f'{HOME}/tensorflow_datasets/climate/'\n",
    "csv_path += 'jena_climate_2009_2016.csv.zip'\n",
    "\n",
    "zip_path = get_file(origin = url, fname = csv_path,\n",
    "                    archive_format='zip',extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TX6uGeeeWIkG"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojHE-iCCWIhz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2009 00:10:00</td>\n",
       "      <td>996.52</td>\n",
       "      <td>-8.02</td>\n",
       "      <td>265.40</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>93.3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1307.75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.75</td>\n",
       "      <td>152.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2009 00:20:00</td>\n",
       "      <td>996.57</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>265.01</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>93.4</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1309.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.50</td>\n",
       "      <td>136.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2009 00:30:00</td>\n",
       "      <td>996.53</td>\n",
       "      <td>-8.51</td>\n",
       "      <td>264.91</td>\n",
       "      <td>-9.31</td>\n",
       "      <td>93.9</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1310.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.63</td>\n",
       "      <td>171.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2009 00:40:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>265.12</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>94.2</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1309.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2009 00:50:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.27</td>\n",
       "      <td>265.15</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>94.1</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>214.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
       "0  01.01.2009 00:10:00    996.52     -8.02    265.40        -8.90    93.3   \n",
       "1  01.01.2009 00:20:00    996.57     -8.41    265.01        -9.28    93.4   \n",
       "2  01.01.2009 00:30:00    996.53     -8.51    264.91        -9.31    93.9   \n",
       "3  01.01.2009 00:40:00    996.51     -8.31    265.12        -9.07    94.2   \n",
       "4  01.01.2009 00:50:00    996.51     -8.27    265.15        -9.04    94.1   \n",
       "\n",
       "   VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
       "0          3.33          3.11          0.22       1.94             3.12   \n",
       "1          3.23          3.02          0.21       1.89             3.03   \n",
       "2          3.21          3.01          0.20       1.88             3.02   \n",
       "3          3.26          3.07          0.19       1.92             3.08   \n",
       "4          3.27          3.08          0.19       1.92             3.09   \n",
       "\n",
       "   rho (g/m**3)  wv (m/s)  max. wv (m/s)  wd (deg)  \n",
       "0       1307.75      1.03           1.75     152.3  \n",
       "1       1309.80      0.72           1.50     136.1  \n",
       "2       1310.24      0.19           0.63     171.6  \n",
       "3       1309.19      0.34           0.50     198.0  \n",
       "4       1309.00      0.32           0.63     214.3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ia-MPAHxbInX"
   },
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-x-GgENynHdx"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVukM9dRipop"
   },
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "  return list(range(-length, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQeGvh7cWXMR"
   },
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "  labels = ['History', 'True Future', 'Model Prediction']\n",
    "  marker = ['.-', 'rx', 'go']\n",
    "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
    "  if delta:\n",
    "    future = delta\n",
    "  else:\n",
    "    future = 0\n",
    "\n",
    "  plt.title(title)\n",
    "  for i, x in enumerate(plot_data):\n",
    "    if i:\n",
    "      plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
    "               label=labels[i])\n",
    "    else:\n",
    "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "  plt.legend()\n",
    "  plt.xlim([time_steps[0], (future+5)*2])\n",
    "  plt.xlabel('Time-Step')\n",
    "  return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                                       target_size, step, single_step=False):\n",
    "    print('start_index:',start_index)\n",
    "    print('end_index:',end_index)\n",
    "    data,labels = [],[]\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "        if single_step:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZCk9fqyJZqX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_index: 0\n",
      "end_index: 300000\n",
      "start_index: 300000\n",
      "end_index: None\n"
     ]
    }
   ],
   "source": [
    "past_history = 720\n",
    "future_target = 72\n",
    "STEP = 6\n",
    "\n",
    "features_considered = ['p (mbar)', 'T (degC)', 'rho (g/m**3)']\n",
    "\n",
    "features = df[features_considered]\n",
    "features.index = df['Date Time']\n",
    "features.head()\n",
    "\n",
    "dataset = features.values\n",
    "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n",
    "data_std = dataset[:TRAIN_SPLIT].std(axis=0)\n",
    "\n",
    "dataset = (dataset-data_mean)/data_std\n",
    "\n",
    "x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, 1], 0,\n",
    "                                                 TRAIN_SPLIT, past_history,\n",
    "                                                 future_target, STEP)\n",
    "x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, 1],\n",
    "                                             TRAIN_SPLIT, None, past_history,\n",
    "                                             future_target, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LImXPwAGRtWy"
   },
   "source": [
    "Let's check out a sample data-point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299280, 120, 3)\n",
      "(299280, 72)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_multi.shape)\n",
    "print(y_train_multi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora mi intento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(DF,ind,Nhistory,Nfuture,columns_in,columns_out):\n",
    "    Nsamples = len(df.index)\n",
    "    if ind-Nhistory > 0 and ind+Nfuture < Nsamples:\n",
    "        inp = DF.iloc[ind-Nhistory:ind][columns_in]\n",
    "        out = DF.iloc[ind:ind+Nfuture][columns_out]\n",
    "        return inp.values, out.values\n",
    "    else: return None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(DF,inds,Nhistory,Nfuture,columns_in,columns_out):\n",
    "    inps, outs = [],[]\n",
    "    for ind in tqdm(inds):\n",
    "        inp,out = get_sample(DF,ind,Nhistory,Nfuture,columns_in,columns_out)\n",
    "        if inp is None or out is None: continue\n",
    "        inps.append( inp )\n",
    "        outs.append( out )\n",
    "    inps = np.array(inps)\n",
    "    outs = np.array(outs)\n",
    "    if len(inps.shape) == 1: inps = np.expand_dims(inps, axis=0)\n",
    "    if len(outs.shape) == 1: outs = np.expand_dims(outs, axis=0)\n",
    "    return inps,outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55670/55670 [01:08<00:00, 807.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Normalize!!\n",
    "cols = df.columns.values[1:]\n",
    "df_num = df[cols]\n",
    "mean = df_num.mean()\n",
    "std = df_num.std()\n",
    "dfn = df.copy()    # dfn = normalized\n",
    "dfn['Date Time'] = pd.to_datetime(dfn['Date Time'],format='%d.%m.%Y %H:%M:%S')\n",
    "dfn = dfn.loc[dfn['Date Time'].apply(lambda x: x.minute) == 0]\n",
    "dfn[cols] = (dfn[cols]-mean)/std\n",
    "\n",
    "Nhistory = int(3*24*60/10)\n",
    "Nfuture  = int(0.5*24*60/10)\n",
    "columns_in = ['p (mbar)', 'T (degC)', 'rho (g/m**3)']\n",
    "\n",
    "columns_out = ['T (degC)']\n",
    "\n",
    "# Random split for train and test\n",
    "inds = np.array(range(Nhistory,len(dfn.index)-Nfuture))\n",
    "#np.random.shuffle(inds)\n",
    "\n",
    "Ntrain = int(len(inds)*0.8)\n",
    "Nvalid = int(len(inds)*0.199)\n",
    "Ntest  = int(len(inds)*0.001)\n",
    "\n",
    "train_ind = inds[:Ntrain]\n",
    "valid_ind = inds[Ntrain:Ntrain+Nvalid]\n",
    "test_ind  = inds[Ntrain+Nvalid:]   # Ntrain+Nvalid+Ntest]\n",
    "\n",
    "train_inp,train_out = prepare_dataset(dfn, train_ind,\n",
    "                                      Nhistory, Nfuture,\n",
    "                                      columns_in, columns_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55669, 432, 3)\n",
      "(55669, 72, 1)\n",
      "[[-1.14288427 -0.98299755  0.63732631]\n",
      " [-1.10340341 -1.01623842  0.68035298]\n",
      " [-1.17638318 -0.97112581  0.61756406]\n",
      " ...\n",
      " [-2.11794185 -1.08628169  0.47297445]\n",
      " [-2.09879962 -1.02929733  0.42219297]\n",
      " [-2.16819022 -1.05897668  0.43219918]]\n"
     ]
    }
   ],
   "source": [
    "print(train_inp.shape)\n",
    "print(train_out.shape)\n",
    "print(train_inp[Nhistory])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasta aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpWDcBkQRwS-"
   },
   "outputs": [],
   "source": [
    "print ('Single window of past history : {}'.format(x_train_multi[0].shape))\n",
    "print ('\\n Target temperature to predict : {}'.format(y_train_multi[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjR4PJArMOpA"
   },
   "outputs": [],
   "source": [
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZcg8FWpSG8K"
   },
   "source": [
    "Plotting a sample data-point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksXKVbwBV7D3"
   },
   "outputs": [],
   "source": [
    "def multi_step_plot(history, true_future, prediction):\n",
    "  plt.figure(figsize=(12, 6))\n",
    "  num_in = create_time_steps(len(history))\n",
    "  num_out = len(true_future)\n",
    "\n",
    "  plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
    "  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
    "           label='True Future')\n",
    "  if prediction.any():\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
    "             label='Predicted Future')\n",
    "  plt.legend(loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCQKetflZRMF"
   },
   "source": [
    "In this plot and subsequent similar plots, the history and the future data are sampled every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6G8bacQR4w2"
   },
   "outputs": [],
   "source": [
    "for x, y in train_data_multi.take(1):\n",
    "  multi_step_plot(x[0], y[0], np.array([0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOjz8DzZ4HFS"
   },
   "source": [
    "Since the task here is a bit more complicated than the previous task, the model now consists of two LSTM layers. Finally, since 72 predictions are made, the dense layer outputs 72 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byAl0NKSNBP6"
   },
   "outputs": [],
   "source": [
    "multi_step_model = tf.keras.models.Sequential()\n",
    "multi_step_model.add(tf.keras.layers.LSTM(32,\n",
    "                                          return_sequences=True,\n",
    "                                          input_shape=x_train_multi.shape[-2:]))\n",
    "multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))\n",
    "multi_step_model.add(tf.keras.layers.Dense(72))\n",
    "\n",
    "multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvB7zBqVSMyl"
   },
   "source": [
    "Let's see how the model predicts before it trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13_ZWvB9SRlZ"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(1):\n",
    "  print (multi_step_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uwOhXo3Oems"
   },
   "outputs": [],
   "source": [
    "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
    "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                          validation_data=val_data_multi,\n",
    "                                          validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKfQoBjQ5l7U"
   },
   "outputs": [],
   "source": [
    "plot_train_history(multi_step_history, 'Multi-Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDg94-yq4pas"
   },
   "source": [
    "#### Predict a multi-step future\n",
    "Let's now have a look at how well your network has learnt to predict the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dt22wq6fyIBU"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(3):\n",
    "  multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOzaIRYBhqwg"
   },
   "source": [
    "## Next steps\n",
    "This tutorial was a quick introduction to time series forecasting using an RNN. You may now try to predict the stock market and become a billionaire.\n",
    "\n",
    "In addition, you may also write a generator to yield data (instead of the uni/multivariate_data function), which would be more memory efficient. You may also check out this [time series windowing](https://www.tensorflow.org/guide/data#time_series_windowing) guide and use it in this tutorial.\n",
    "\n",
    "For further understanding, you may read Chapter 15 of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/), 2nd Edition and Chapter 6 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
