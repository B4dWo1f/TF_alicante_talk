{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional, only for Jupyter\n",
    "%matplotlib notebook\n",
    "\n",
    "# General libraries\n",
    "import numpy as np                # to deal with arrays, vectors, matrices...\n",
    "import matplotlib.pyplot as plt   # to plot the data\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tensorflow\n",
    "import os\n",
    "HOME = os.getenv('HOME')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # to get rid of the TF compilation warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape, Flatten\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only because my system-wide config is tuned, you don't need these lines\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = 5,3\n",
    "mpl.rcParams['font.size'] = 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "url = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip'\n",
    "csv_path = f'{HOME}/tensorflow_datasets/climate/'\n",
    "csv_path += 'jena_climate_2009_2016.csv.zip'\n",
    "\n",
    "zip_path = get_file(origin = url, fname = csv_path,\n",
    "                    archive_format='zip',extract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data and fix format if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert dates & sort\n",
    "df0['Date Time'] = pd.to_datetime(df0['Date Time'],format='%d.%m.%Y %H:%M:%S')\n",
    "df0 = df0.sort_values(by='Date Time')\n",
    "\n",
    "print(len(df0.index.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,12))\n",
    "n = len(df0.columns[1:])\n",
    "gs = gridspec.GridSpec(n, 1)\n",
    "axs = []\n",
    "for i in range(n):\n",
    "    if i == 0:\n",
    "        axs.append( fig.add_subplot(gs[i, 0]) )\n",
    "    else:\n",
    "        axs.append( fig.add_subplot(gs[i, 0],sharex=axs[0]) )\n",
    "\n",
    "for i,col in enumerate(df0.columns[1:]):\n",
    "    axs[i].plot(df0['Date Time'], df0[col])\n",
    "    axs[i].set_xlabel('DateTime')\n",
    "    axs[i].set_ylabel(col)\n",
    "fig.tight_layout()\n",
    "plt.sho()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registers every 10 min, let's consider one register per hour (RAM, CPU...)\n",
    "df0 = df0.loc[df0['Date Time'].apply(lambda x: x.minute) == 0]\n",
    "\n",
    "# Only 1 register for 2017, we skip it\n",
    "df0 = df0.loc[df0['Date Time'].apply(lambda x: x.year) < 2017]\n",
    "\n",
    "T0 = None\n",
    "if not T0 is None:\n",
    "    T0 = dt.datetime(2015,1,1)\n",
    "    df = df[df['Date Time'] > T0]\n",
    "\n",
    "Nsamples = len(df0.index.values)\n",
    "print(Nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "X = [x.replace(year=2020) for x in df0['Date Time']]\n",
    "Y = df0['T (degC)']\n",
    "C = [x.year for x in df0['Date Time']]\n",
    "\n",
    "img = ax.scatter(X, Y, c=C, cmap='cool')\n",
    "cbar = fig.colorbar(img) #, orientation='horizontal', shrink=0.8)\n",
    "\n",
    "cbar.ax.set_ylabel('Year')\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b\\n%d'))\n",
    "ax.set_title('By Year')\n",
    "ax.set_ylabel('T (°C)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "X = [x.time() for x in df0['Date Time']]\n",
    "C = [x.month for x in df0['Date Time']]\n",
    "Y = df0['T (degC)']\n",
    "\n",
    "img = ax.scatter(X, Y, c=C, cmap='cool')\n",
    "cbar = fig.colorbar(img) #, orientation='horizontal', shrink=0.8)\n",
    "\n",
    "cbar.ax.set_ylabel('Month')\n",
    "ax.set_title('By Month')\n",
    "ax.set_ylabel('T (°C)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions to interact with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(DF,ind,Nhistory,Nfuture,col='T (degC)',pred=None):\n",
    "    try:\n",
    "        X0 = DF.iloc[ind-Nhistory:ind]['Date Time']\n",
    "        X1 = DF.iloc[ind:ind+Nfuture]['Date Time']\n",
    "        fmt = '%-d/%-m/%y\\n%H:%M'\n",
    "    except KeyError:\n",
    "        X0 = range(ind-Nhistory,ind)\n",
    "        x0 = len(X0)\n",
    "        X1 = range(ind,ind+Nfuture)\n",
    "        fmt = ''\n",
    "    Y0 = DF.iloc[ind-Nhistory:ind][col]\n",
    "    Y1 = DF.iloc[ind:ind+Nfuture][col]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(X0,Y0, 'C0', label='input')\n",
    "    ax.plot(X1,Y1, 'C1', label='output')\n",
    "    if pred is not None:\n",
    "        ax.plot(X1,pred, 'C2', label='NN pred')\n",
    "    if len(fmt) > 0:\n",
    "        # there are dates\n",
    "        X1_base = pd.date_range(min(X1),max(X1))\n",
    "        Y1_base = base_line(df_valid,min(X1),max(X1),cols=['T (degC)'])\n",
    "        ax.plot(X1_base,Y1_base, 'C3', label='BaseLine')\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(fmt))\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_line(DF,start,end,cols=['T (degC)']):\n",
    "    aux = DF.copy()\n",
    "    aux = aux.groupby([aux['Date Time'].apply(lambda x: x.month),\n",
    "                       aux['Date Time'].apply(lambda x: x.day)]).mean()\n",
    "    ret = []\n",
    "    for date in pd.date_range(start, end):\n",
    "        ret.append(aux.loc[date.month].loc[date.day][cols].values)\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Normalize!!\n",
    "norm = True\n",
    "if norm:\n",
    "    cols = df0.columns.values[1:]   # skip date\n",
    "    df_num = df0[cols]\n",
    "\n",
    "    mean = df_num.mean()\n",
    "    std = df_num.std()\n",
    "\n",
    "    df = df0.copy()\n",
    "    df[cols] = (df[cols]-mean)/std\n",
    "else:\n",
    "    df = df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Input/Output data\n",
    "\n",
    "We will use the weather of the past 5 days to predict the weather of the next 12 hours.\n",
    "The data is collected every 10 min (with some exceptions that we are going to ignore), that means that we need:\n",
    "\n",
    "Input: $5\\text{days}\\times 24\\text{hours}\\times 60\\text{hours}/10\\text{min between samples} = 720\\text{samples}$\n",
    "\n",
    "Output: $0.5\\text{days}\\times24\\text{hours}\\times60\\text{hours} / 10\\text{min between samples} = 72 \\text{samples}$\n",
    "<img src='inp_out.svg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df.loc[df['Date Time'].apply(lambda x:x.year)<2016]\n",
    "#df_valid = df.loc[df['Date Time'].apply(lambda x:x.year)>=2016]\n",
    "\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "df_train = df[msk]\n",
    "df_valid = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inp_out(DF,Nhistory,Nfuture,columns_in,columns_out,step=6):\n",
    "    IN,OUT = [],[]\n",
    "    for ind in tqdm(range(Nhistory,len(DF.index)-Nfuture)):\n",
    "        indices = range(ind-Nhistory, ind, step)\n",
    "        inp = DF.iloc[indices][columns_in].values\n",
    "        out = DF.iloc[ind:ind+Nfuture][columns_out].values\n",
    "        IN.append(inp)\n",
    "        OUT.append(out)\n",
    "    return np.array(IN),np.array(OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Nhistory = int(5*24*60/10)\n",
    "Nfuture  = int(6*60/10)\n",
    "# columns_in  = ['T (degC)']\n",
    "columns_in  = ['p (mbar)', 'T (degC)', 'rho (g/m**3)']\n",
    "columns_out = ['T (degC)']\n",
    "\n",
    "x_train,y_train = prepare_inp_out(df_train,Nhistory,Nfuture,columns_in,columns_out)\n",
    "inp_shape = x_train.shape[1:]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid,y_valid = prepare_inp_out(df_valid,Nhistory,Nfuture,columns_in,columns_out)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sample(df_valid,Nhistory+1,Nhistory,Nfuture,col='T (degC)',pred=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = tf.data.Dataset\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "valid_data = valid_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=inp_shape))\n",
    "model.add(tf.keras.layers.LSTM(16, activation='relu'))\n",
    "model.add( Dense(100, activation='relu') )\n",
    "model.add( Dense(Nfuture*len(columns_out),activation='linear') )\n",
    "model.add( Reshape((Nfuture,len(columns_out))) )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(clipvalue=1.0), loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_data,\n",
    "                    epochs=50,\n",
    "                    steps_per_epoch=200,\n",
    "                    validation_data=valid_data,\n",
    "                    validation_steps=50,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = history.history['loss']\n",
    "val_err = history.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(err,label='loss')\n",
    "ax.plot(val_err,label='val_los')\n",
    "ax.legend()\n",
    "ax.set_ylim([0,min([20,np.max(val_err)])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check unseen examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = model.predict(x_valid)\n",
    "print(outs.shape)\n",
    "print(model.evaluate(x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    ind = np.random.randint(0,len(outs))\n",
    "    visualize_sample(df_valid,ind,Nhistory,Nfuture,col='T (degC)',pred=outs[ind])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
