{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning for physicists\n",
    "<center><img src=\"cover.svg\" style=\"width: 400px;\"/></center>\n",
    "### Noel García Martínez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ~~Machine Learning~~ for ~~physicists~~\n",
    "# Neural Networks* for dummies\n",
    "\n",
    "<center><img src=\"cover.svg\" style=\"width: 400px;\"/></center>\n",
    "*and only the easy type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scope of this ~~master~~ amateur-class\n",
    "<center><img src=\"mount_stupid.svg\" style=\"width: 600px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First... what ML is **NOT**\n",
    "\n",
    "<br>\n",
    "<center><img src=\"robots.png\" style=\"height: 170px;\"/></center>\n",
    "<br>\n",
    "\n",
    "- It's **not** SciFi-taking-over-the-world technology  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First... what ML is **NOT**\n",
    "\n",
    "<br>\n",
    "<center><img src=\"magic.png\" style=\"height: 200px;\"/></center>\n",
    "<br>\n",
    "\n",
    "- It's **not** SciFi-taking-over-the-world technology (...yet)  \n",
    "- It's **not** the magic solution for any and all problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What ML really is...\n",
    "\n",
    "...overhyped and boring statistics and algebra\n",
    "\n",
    "<center><img src=\"algebra.png\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "(and with a terrible notation!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Before we start\n",
    "Some useful libraries\n",
    "- pyBrain: http://pybrain.org/  \n",
    "> Nice documentation & tutorial. Very limited.\n",
    "- scikit-learn: https://scikit-learn.org  \n",
    "> Very efficient. Lots of tools and predefined models. Difficult to extend\n",
    "- TensorFlow: https://www.tensorflow.org/  \n",
    "> Mantained and developed by Google. Initially quite complex and difficult to use (computational graphs, sessions...) but with __keras__ or ___since v2.0__ it's quite simple. __Extremely powerful__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's Begin\n",
    "### Machine Learning Vs. Artificial Intelligence Vs. Deep Learning Vs. ...\n",
    "\n",
    "<center><img src=\"landscape.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's Begin\n",
    "### Machine Learning Vs. Artificial Intelligence Vs. Deep Learning Vs. ...\n",
    "\n",
    "<center><img src=\"landscape1.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Demystifying...\n",
    "\n",
    "<center><img src=\"ANN.svg\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "A Neural Network is a mathematical function that maps vectors $\\vec{v}\\in\\mathbb{R}^n$ to vectors $\\vec{v}'\\in\\mathbb{R}^m$\n",
    "- They are a function more or less complex to calculate (like sin, log...)\n",
    "- They usually have **a lot** of parameters that can be tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Demystifying...\n",
    "- The parameters are tuned by training on examples\n",
    "<center><img src=\"ANN_super.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Demystifying...\n",
    "- The parameters are tuned by training on examples\n",
    "<center><img src=\"ANN_super1.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Gutting the beast...\n",
    "Each of the nodes in the diagram (a neuron) is real function, normally a sigmoid\n",
    "<center><img src=\"sigmoid0.svg\" style=\"width: 600px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Gutting the beast...\n",
    "Each of the nodes in the diagram (a neuron) is real function, normally a sigmoid\n",
    "<center><img src=\"sigmoid1.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# So... What is a Neural Network?\n",
    "## Gutting the beast...\n",
    "Each of the nodes in the diagram (a neuron) is real function, normally a sigmoid\n",
    "<center><img src=\"sigmoid2.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Gutting the beast...\n",
    "Each of the nodes in the diagram (a neuron) is real function, normally a sigmoid\n",
    "<center><img src=\"2sigmoid0.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Gutting the beast...\n",
    "Each of the nodes in the diagram (a neuron) is real function, normally a sigmoid\n",
    "<center><img src=\"2sigmoid1.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Gutting the beast...\n",
    "Each of the nodes in the diagram (a neuron) is real function, normally a sigmoid\n",
    "<center><img src=\"2sigmoid2_0.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Gutting the beast...\n",
    "Each of the nodes in the diagram (a neuron) is real function, normally a sigmoid\n",
    "<center><img src=\"2sigmoid2_1.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Gutting the beast...\n",
    "Each of the nodes in the diagram (a neuron) is real function, normally a sigmoid\n",
    "<center><img src=\"2sigmoid2_2.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Gutting the beast...\n",
    "Each of the nodes in the diagram (a neuron) is real function, normally a sigmoid\n",
    "<center><img src=\"2sigmoid2_3.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# So... What is a Neural Network?\n",
    "## Gutting the beast...\n",
    "Each of the nodes in the diagram (a neuron) is real function, normally a sigmoid\n",
    "\n",
    "<center><img src=\"2sigmoid2_3f.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now, the training\n",
    "\n",
    "<center><img src=\"ANN1.svg\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "We define an \"Error\" or \"Loss\" function, which determines how bad is the NN responding\n",
    "$$\\mathcal{E}(y,y_0) = \\text{Error}(W_1, W_2,\\dots W_n, b_1, b_2,\\dots b_n)$$\n",
    "- Different functions.\n",
    " - MSE, crossentropy... (TF provides ~20, + custom functions)\n",
    "- The goal is to minimize the Loss function\n",
    "- Usually >100k parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Back-Propagation & Gradient descent\n",
    "\n",
    "- Gradient descent: Algorithm to reach the minumium as fast as possible\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"error3d.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Back-Propagation & Gradient descent\n",
    "\n",
    "- Gradiend descent: Algorithm to reach the minumium as fast as possible\n",
    " - Possibly hundreds of local minima\n",
    " - There are many Gradient descent algorithms (TF provides ~10)\n",
    "\n",
    "<center><img src=\"error3d0.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Back-Propagation & Gradient descent\n",
    "\n",
    "- Gradiend descent: Algorithm to reach the minumium as fast as possible\n",
    " - Possibly hundreds of local minima\n",
    " - There are many Gradient descent algorithms (TF provides ~10)\n",
    " - Still some parameters to tweak\n",
    "\n",
    "<center><img src=\"error3d1.svg\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Back-Propagation & Gradient descent\n",
    "\n",
    "- Gradiend descent: Algorithm to reach the minumium as fast as possible\n",
    " - Possibly hundreds of local minima\n",
    " - There are many Gradient descent algorithms (TF provides ~10)\n",
    " - Still some parameters to tweak (learning rate...)\n",
    "\n",
    "## How to calculate the gradient: Backpropagation\n",
    "\n",
    "- Chain Rule\n",
    "\n",
    "$$(f\\circ g)' = (f'\\circ g)\\cdot g'$$\n",
    "\n",
    "\n",
    "$$\\frac{dz}{dx} = \\frac{dz}{dy}\\frac{dy}{dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Back-Propagation & Gradient descent\n",
    "\n",
    "- Gradiend descent: Algorithm to reach the minumium as fast as possible\n",
    " - Possibly hundreds of local minima\n",
    " - There are many Gradient descent algorithms (TF provides ~10)\n",
    " - Still some parameters to tweak\n",
    "\n",
    "## How to calculate the gradient: Backpropagation\n",
    "\n",
    "- Chain Rule\n",
    "\n",
    "$$\\nabla\\mathcal{E}(W^n,W^{n-1},...)\"=\"\\frac{\\partial\\mathcal{E}}{\\partial z^n}\\frac{\\partial z^n}{\\partial W^{n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Back-Propagation & Gradient descent\n",
    "\n",
    "- Gradiend descent: Algorithm to reach the minumium as fast as possible\n",
    " - Possibly hundreds of local minima\n",
    " - There are many Gradient descent algorithms (TF provides ~10)\n",
    " - Still some parameters to tweak\n",
    "\n",
    "## How to calculate the gradient: Backpropagation\n",
    "\n",
    "- Chain Rule\n",
    "\n",
    "$$\\nabla\\mathcal{E}(b^n,b^{n-1},...)\"=\"\\frac{\\partial\\mathcal{E}}{\\partial z^n}\\frac{\\partial z^n}{\\partial b^{n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Back-Propagation & Gradient descent\n",
    "\n",
    "- Calculate gradient\n",
    "- Update all weights and biases along the gradient\n",
    "- Check new error\n",
    "- Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# General Steps\n",
    "## Get data & explore data\n",
    "### Get\n",
    "- Download from server, scrap web, ...\n",
    "- Measure quantity, collect information\n",
    "- ~~Steal private data~~ Convince users to give you all the personal data\n",
    "- ...\n",
    "\n",
    "### Explore\n",
    "+ Number of samples (are they enough? too many (RAM)?...)\n",
    "+ Ranges of each variable\n",
    "+ NaN, null, missing..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# General Steps\n",
    "## Prepare data\n",
    "- Fix NaN, null, missing, ...\n",
    "- Normalize?\n",
    "- Special structures: (np.)array, (tf.)DataSet, ...\n",
    "- Train & Validation split (validation vs test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# General Steps\n",
    "## Design model\n",
    "- Types of layers\n",
    "- Number of layers\n",
    "- Units per layer\n",
    "- Optimizer & Loss (classification vs regression)\n",
    "\n",
    "## Fit\n",
    "- Epochs\n",
    "- many fine-tune parameters for more advanced problems\n",
    "\n",
    "## Check fit\n",
    "- Check the learning curve\n",
    "- Over/under-fitting?\n",
    "- Accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# General Steps\n",
    "## evaluate\n",
    "- Check on the whole validation/testing dataset\n",
    "\n",
    "## use\n",
    "- Now you are a DeepLearning expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Before we start\n",
    "\n",
    "## ~~Boring~~ Details\n",
    "- Both inputs and outputs should have dimensions:\n",
    "$$N_{\\text{samples}}\\quad\\times\\quad N_{dimension}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Before we start\n",
    "\n",
    "## ~~Boring~~ Details\n",
    "- Both inputs and outputs should have dimensions:\n",
    "$$N_{\\text{samples}}\\quad\\times\\quad N_{dimension}$$\n",
    "- Architecture = Art (and magic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Before we start\n",
    "\n",
    "## ~~Boring~~ Details\n",
    "- Both inputs and outputs should have dimensions:\n",
    "$$N_{\\text{samples}}\\quad\\times\\quad N_{dimension}$$\n",
    "- Architecture = ~~Art (and magic)~~ Experience\n",
    "- Default Loss functions to start with\n",
    "\n",
    "|  Problem   | Loss function |\n",
    "|---|---|\n",
    "| Regression | Min Square Error (mse)   |\n",
    "|            | Min Absolute Error (mae) |\n",
    "| Classification (2 labels) | Binary CrossEntropy |\n",
    "|                           | Hinge |\n",
    "| Classification (multi lab) | Categorical CrossEntropy |\n",
    "|                            | Sparse Categorical CrossEntropy |\n",
    "\n",
    "*But complex problems require complex loss-functions"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "rise": {
   "height": 768,
   "width": 1024
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
